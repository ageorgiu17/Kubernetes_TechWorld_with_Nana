{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Kubernetes</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>What is k8s? <h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kubernetes este un sistem de orchestrare a containerelor open source dezvoltat de către Google. Acest sistem se ocupă cu partea de manageriere de containere (fie că sunt containere de tip Docker sau alte containere). Kubernetes ne ajută să manageriem aplicații care sunt create din sute sau mii de containere și ne ajută să le manageriem în environment-uri diferite precum mașini fizice (laptopuri, calculatoare), mașini virtuale sau pe cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Ce tip de problemă rezolvă Kubernetes?\n",
    "\n",
    "Care sunt task-urile unui sistem de orchestrare a containerelor?</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creșterea numărului de microservicii a dus la o creștere de utilizare a containerelor deoarece un container reprezintă ideea cea mai bună pentru o aplicație mică ce utilizează microservicii. Creșterea acestora au dus la apariția a unor aplicații create din sute sau chiar din mii de containere. Managerierea acelor containere în mai multe environment-uri  folosind script-uri sau anumite tool-uri create manual reprezintă un pas extrem de complex sau chiar imposibil. Acest scenariu a dus la nevoie de a avea tool-uri pentru orchestrarea containerelor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ceea ce oferă aceste tool-uri: \n",
    "\n",
    "    - High availability = acest lucru înseamnă că aplicația nu are downtime, tot timpul putând fi accesată de către utilizator\n",
    "    \n",
    "    - Scalability = aplicația are o perfomanță extrem de bună, se încarcă extrem de repede iar utilizatorii au o rată de răspuns din partea aplicației foarte mare\n",
    "\n",
    "    - Disaster Recovery = dacă o infrasctructură are o anumită problemă precum pierderea unor date sau probleme de server, infrastructura trebuie să aibă ceva mecanims de back-up pentru date pentru ca aplicația să nu piardă date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Componentele K8s</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Nodes sau Pods</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O să începem cu un setup basic al unui <i>worker node</i> (sau doar 'node' în kubernetes), care reprezintă un simplu server, fizic sau o mașină virtuală, iar componenta cea mai basic, sau cea mai mică unitate din kubernetes este un 'Pod'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Pod' este o abstracție al unui container. Un 'pod' creează un envoironment ce rulează, sau un layer peste un container, motivul fiind faptul că kubernetes dorește să abstractizeze partea de rulare a containerelor sau tehnologiile din container pentru a putea fi înclocuite dacă se dorește sau pentru faptul că nu trebuie să lucrăm cu tehnologia de Docker, ci doar pentru a interacționa cu acel layer de kubernetes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dacă o aplicație este cretă din mai multe containere, de cele mai multe ori în cadrul unui 'Pod' se rulează un singur container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cum anume comunică cele 2 pod-uri în cadrul kubernetes? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kubernetes oferă un IP virtual, iar asta înseamnă că fiecare pod din cadrul aplicației o să primească propria adresă de IP unică. Fiecare pod poate comunica cu alt pod prin intermediul acelui IP virtual. Pod-urile în kubernetes sunt ephemerale, adică pot să 'moară' foarte ușor. În cazul acesta, dacă un pod dispare deoarece este o problemă în container și rezultă cu un crash, atunci un nou pod o să fie creat în locul lui, iar în momentul recreeri pod-ului, o nouă adresă IP virtuală o să fie assignată acelui Pod, ceea ce este incovenient în cazul în care se face comunicare între Pod-uri utilizând adresele IP. Din cauza acestei probleme, altă componentă de Kubernetes este utilizată, și anume 'Service'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Service</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Service' reprezintă o adresă IP statică (permanentă) care poate fi atașată fiecărui Pod în parte. O aplicație împărțită în 2 containere, unul cu aplicația principală și altul cu o bază de date, atunci Pod-ul cu container-ul aplicației o să aibă propriul 'Service', iar Pod-ul pentru baza de date o să aibă propriul 'Service', iar partea bună aici este faptul că durata de viață a unui 'Service' și a unui Pod nu sunt conectate, atunci chiar dacă un Pod o să 'moară', 'Service'-ul și adresa IP virtuală o să rămână."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "În cazul în care dorim ca o aplicație să fie accesibilă din cadrul unui browser extern, trebuie să creem un 'Service' extern. Un 'Service' extern este un service care deschide comunicarea din surse externe, dar în mod normal nu dorim ca baza de date să aibă un service extern care să fie disponibil pentru request-urile publice, iar pentru situația de baze de date trebuie creat un service intern. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>ConfigMap și Secrets</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pod-urile după cum știm comunică între ele cu ajutorul unui Service. Aplicația cu 2 containere (unul pentru aplicația în sine, iar celălalt pentru baza de date) o să conțină un endpoint 'mongo-db-service' utilizat pentru a comunica cu baza de date, însă unde anume se confiră acest url pentru a face legătura cu baza de date? De obicei se face în fișierul de proprietăți al aplicației sau prin cadrul unei variabie de sistem externe, dar de cele mai multe ori este în imaginea aplicației (cea cu care se creează container-ul). În situația în care numele Serice-ului se modifică din 'mongo-db-service' în 'mongo-db' trebuie să modificăm acest endpoint în cadrul aplicației. Acest lucru însemană reconstrucția imaginii, push în repo pe docker-hub, pull pentru imaginea nouă în pod-ul respectiv și restartarea întregului proces. Un pic prea mulți pași pentru o simplă modificare de endpoint a bazei de date. Pentru a rezolva problema aceasta, kubernetes ne oferă partea de 'ConfigMap'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'ConfigMap' reprezintă configurația externă a aplicației. Acesta o să conțină date precum url-uri către baza de date sau alte servicii ce le utilizăm, iar în kubernetes se conectează la un pod, iar acel pod își ia datele din cadrul acelui 'ConfigMap'. Parte din cadrul datelor pentru o bază de date pot să fie reprezentate și de către un user cu parloa acestuia, date care de asemenea se pot modifica. Trecerea acestor date în cadrul 'ConfigMap' sub formă de text nu este recomandat deoarece nu este asigurată aplicația respectivă, iar pentru a rezolva această problemă, kubernetes are o altă componentă denumită 'Secrets'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Secrets</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Secrets' este asemănător cu 'ConfigMap' însă este utilizat pentru a stoca date secrete (precum user și password), datele fiind trecute în formatul base64 encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Volumes</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acum o să ne uităm un pic peste un alt element important din cadrul unei aplicații, și anume stocarea datelor și cum funcționează acest concept în kubernetes. Aplicația cu baza de date (explicată mai sus) are ceva date în interiorul acesteia sau produce date noi cât timp rulează aplicația. Cu conceptele de mai sus, în cazul în care Pod-ul pentru baza de date moare, datele ce au fost create cât timp a fost activ acel pod o să dispară. Modul prin care se pot păstra aceste date este prin utilizarea de Volume (precum volumele din Docker). Un volum atașează o memorie fizică de pe hard către pod-ul pentru baza de date. Acea memorie poate să fie ori pe mașina locală (pe același server node pe care rulează pod-ul) sau poate fi o memorie remote, adică în afara clusterului kubernetes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partea de volume este importantă deoarece kubernetes nu se ocupă și cu partea de persistența datelor, este de datoria utilizatorului să se asigure că aceste date sunt păstrate și au back-ul necesar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Deployment and Stateful Set</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Din acest moment, aplicația este setată și user-ul o poate accesa dintr-un browser extern. Ce se întâmplă în situațua în care pod-ul cu aplicația de bază moare? În acest caz o să avem un moment de downtime al aplicației în care user-ul nu poate accesa aplicația respectivă (nerecomandat). În loc se ne bazăm doar pe un singur pod al aplicației sau al bazei de date, o să replicăm acestea în cadrul mai multor servere. O să avem alt Node unde o replică a aplicației o să ruleze care este de asemenea conectată la același 'Service'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un 'Service' are 2 funcționalități importante, oferă un IP permanent, static cu un nume constant de DNS pentru a nu fi nevoiți de fiecare dată să modificăm endpoint-ul atunci când un Pod moare, iar ca și a doua funcționalitate, Service reprezintă un 'load balancer', adică Service-ul o să prindă request-ul și o să îl trimită mai departe către orice Pod este listat ca fiind ocupat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pentru a crea o a doua replică a aplicației nu o să creem un pod secund, ci o să creem un blueprint al container-ului de aplicație și o să specificăm câte replici ale acelui pod dorim să ruleze, iar acel blueprint poartă denumirea de 'Deployment'. În practică nu o să lucrăm cu pod-uri, ci o să creem aceste blueprint (Deployment). După cum un pod reprezintă un layer abstractizat pentru un container, un Deployment este un alt layer abstractizat peste pods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Stateful Set</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "În cazul acesta, dacă pod-ul aplicației o să dea crash, atunci Service-ul o să facă forward la request către alt pod care rulează pentru ca aplicație să fie accesibilă pentru utilizator. Ce se poate face pentru pod-ul care se ocupă cu partea de baze de date? Dacă acel pod moare, atunci aplicația din nou nu o să fie accesibilă de către utilizator. Ideea este că nu se pot replica baze de date utilizând conceptul de 'Deployment', iar motivul pentru acesta este faptul că o bază de date are un anume 'state', care reprezintă datele din interiorul bazei respective. În cazul în care avem clone ale aceleași baze de date, toate trebuie să acceseze aceleași date, lucru care necesită un mecanism pentru a verifica care anume pod rulează query-uri de scriere în baza de date sau ce pod-uri preia date din baza de date. Acest mecanism este oferit de către kubernetes prin 'Stateful Set'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acest concept este utilizat în special pentru aplicații ce utilizează și baze de date. Precum 'Deployment', 'Stateful Set' se ocupă cu partea de replicare a pod-urilor și se asigură că partea de scriere și citire din baza de date sunt sincronizate pentru a nu oferi inconsistențe în baza de date. Totuși, partea de deploy pentru 'Stateful Set' în clustere de Kubermetes nu este tocmai ușoară"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>K8s Architecture</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Node Processes</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una dintre componentele principale din kubernetes este reprezentată de 'worker service' ('nodes'). Fiecare 'Node' o să aibă mai multe pod-uri care rulează în cadrul acelui 'Node'. Modul prin care kubernetes realizează acest lucru este prin intermediul a 3 procese care trebuie instalate pentru fiecare 'Node' care este utilizat pentru a programa și a manageria acele părți. 'Nodes' reprezintă partea dintr-un cluster kubernetes care practic lucrează (de aici și denumirea de 'Worker Nodes')."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primul proces care trebuie să ruleze pentru fiecare 'Node' este procesul de container (container runtime, docker de exemplu). Deoarece pod-urile aplicației au containere care rulează în interior, un container runtime trebie să fie instalat în cadrul fiecărui Node, dar procesul care se ocupă cu partea de programare pentru pod-uri și containerele pentru care rulează acele pod-uri este 'Kubelet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Kubelet' este un proces de ține de kubernetes care are interfațe pentru atât partea de container runtime cât și pentru Node-ul în sine. Kubelet este responsabil să ia configurația respectivă și să ruleze sau să pornească un anume Pod (cu un container respectiv) și să assigneze resurse din acel Node pentru container (CPU, RAM, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De cele mai multe ori un cluster kubernetes este creat din mai multe Nodes, fiecare dintre ele având procesele de container runtime (Docker) și Kubelet. Modul prin care node-urile comunică între ele în cadrul unui cluster este prin 'Services', acesta preia request-ul făcut către un anumit Pod și în redirecționează către un anume Pod."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al treilea proces care se ocupă cu partea de redirecționare a unui request către un anume Pod poartă denumirea de 'Kube Proxy', fiind necesar și acesta să fie instalat pe fiecare Node în parte. 'Kube proxy' are un mecanism inteligent de redirecționare care se asigură că această comunicare se face într-un mod performat prin care redirecționeazî request-ul către pod-uri din același Node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>\n",
    "\n",
    "Cum se interacționează cu acest cluster kubernetes?\n",
    "\n",
    "Cum se decide pe ce nod sau pod aplicația o să fie programată?\n",
    "\n",
    "Dacă un pod moare, ce proces se ocupă cu partea de monitorizare și repornire? \n",
    "\n",
    "Când se adaugă un nou server cum se alătură cluster-ului pentru a deveni un nou Node? </h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pentru a răspunde la întrebările de mai sus, trebuie să aruncăm o privire peste 'Master Node'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Master Node</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un 'Master Node' are procese complet diferite care rulează în interiorul lor. Există 4 procese care rulează pe fiecare 'Master Node' ce controlează 'cluster state' și 'Worker Node'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primul proces este 'API Server'. Atunci când ca user dorești să faci deploy la o nouă aplicație într-un cluster de kubernetes o să interacționezi cu un 'API Server' prin intermediul unui 'client' (interfață grafică, linie de comandă (kubelet), Kubernetes API)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Scheduler</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un alt proces este cel 'Scheduler'. Atunci când se face un request la serverul API pentru a programa un anumit Pod, după ce acest request este validat acesta este trimis către 'Scheduler' pentru a porni un Pod al aplicației în cadrul unuia dintre nod-uri (worker node). Pod-ul o să fie pornit pe un Node care utilizează cele mai puține resurse, nu se pornește un Pod random pe un anumit Node, acest sistem are un mecanism inteligent de programare. Acest 'Scheduler' doar decide pe ce Node acest Pod o să fie pornit, procesul care pornește acel Pod este 'Kubelet'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Controller Manager</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acest proces detectează schimbări în cluster, precum crash a unui anumit Pod dintr-un anumit Worker Node. Când detectează că un Pod a murit, face un request la 'Scheduler' pentru a reporni acele Pod-uri care au murit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>etcd</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acesta este o stocare de tipul key-value pentru partea de 'cluster state'. Putem să ne imagină ca fiind creierul clusterului. Orice schimbare ce se petrece în cadrul unui cluster (reprogramare unui Pod, dacă a murit un Pod) sunt salvate sau updatate în acest sistem de stocare key-value. Motivul pentru care aceste 'etcd' este considerat ca fiind creierul clusterului este pentru faptul că toate procesele de mai sus funcționează datorită datelor din cadrul clusterului (date stocate în etcd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Cluster example</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Într-un cluster kubernetes mic o să avem cel mai probabil 2 Master Nodes și 3 Worker Nodes. Deși Master Nodes sunt mai importante, acestea consumă mai puține resurse deoarece toată treaba este realizată de către WOrker Nodes. Un Master Nodes. Fiecare Node o să aibă o proprie mașină (fie fizică sau virtuală). Dacă se dorește să se testeze ceva local, setarea unui cluster este extrem de dificilă, poate chiar imposibilă deoarece este nevoie de resurse mari (CPU, RAM). Pentru acest pas de testare locală se poate uiliza 'Minikube'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Minikube</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minikube este un Node din Cluster unde procesele din Master Node și Worker Node funcționează pe același Node. Modul prin care acestea rulează este cu ajutorul unui VM. Minikube este un cluster de 1 Node din Kubernetes care rulează pe un Vortual Box. Din moment ce avem acest Node pe mașina locală în cluster, avem nevoie de un mod de a interacționa cu acest Node. Această interacțiune se face cu 'kubectl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>kubectl</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'kubectl' este o linie de comandă pentru clusterele kubernetes. Cum se preciza, atât procese de la Worker Node și Master Node rulează pe același Node cu 'minikube', iar unul dintre procesele ce rulează din Master Node este cel de API Server. Pentru a realiza orice modificări în clusterul de Kubernetes întâi trebuie să interacționă cu API-ul de la server. Interacțiunea acesta se poate face fie printr-o interfață grafică, fie prin API-ul de Kubernetes, fie prin linia de comandă (care este kubetcl). 'kubectl' reprezintă cel mai puternic mod de interacțiune cu API Server deoarece prin linia de comandă se pot realiza toate comenzile din kubernetes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pentru a putea crea acest cluster local trebuie să instalăm următoarele tehnologii:\n",
    "\n",
    "    1. minikube\n",
    "\n",
    "    2. kubectl\n",
    "\n",
    "    3. VirtualBox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "După ce am instalat aceste tehnologii putem să creem un cluster de kubernetes. Pentru a crea acest cluster o să se utilizeze 'minikube'. Comanda pentru a crea un cluster este 'start'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "minikube start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./ScreenShots/minikube_start.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "După ce am pornit cluster-ul local, putem verifica Node-urile din acest cluster. Pentru a verifica nodurile se va utiliza 'kubectl'. Acestei comenzi i se va adăuga 'get nodes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "kubectl get nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./ScreenShots/kubectl_get_nodes.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'minikube' se va utiliza doar pentru a crea, a porni, a opri sau a șterge un cluster local. Pentru restul acțiunilor ce țin de cluster o să ne folosim de 'kubectl'. Linia de comandă 'kubectl' se poate folosi și pentru clustere de producție găsite pe un cloud sau pe mașini virtuale, nu este specific doar pentru 'minikube'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Basic kubelet commands</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "În acest moment avem un cluster format cu 'minikube' și linia de comandă 'kubectl' instalată. Din moment ce clusterul este setat, o să ne folosim de 'kubectl' pentru a face orice modificări în interiorul clusterului. Pentru a vedea Nodes care sunt prezente în cadrul clusterului am observat că se utilizează comanda 'kubectl get nodes'. În ceea ce privește Pods, pentru a vedea toate Pods se utilizează comanda 'kubectl get pod'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "kubectl get pod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src ='./ScreenShots/kubectl_get_pod.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "În acest moment se poate observa că în cadrul acestui cluster nu există niciun Pod care rulează."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pentru parte de Service din cadrul unui Node se va utiliza comanda 'kubectl get service'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./ScreenShots/kubectl_get_service.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prin comanda de mai sus ni se afișează datele referitoare la partea de Service din cadrul Node. În aceste date se găsește adresa IP a clusterului respectiv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Din moment ce nu avem niciun Pod în cadrul Clusterului, o să începem să creem. Pentru a crea componente în cadrul clusterului o să se utilizeze comanda 'create' din 'kubectl'. Dacă se utilizează --help pentru 'kubectl create' se va observa că nu există o comandă ca să creeze un Pod."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./ScreenShots/kubectl_create_help.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu există opțiunea de a crea un Pod deoarece modul în care kubernetes funcționează, un Pod este cea mai mică unitate din cadrul clusterului , dar în practică nu o să creem Pods sau nu o să lucrăm cu Pods, există un layer abstract peste Pods care poartă denumirea de Deployment (cum este specificat mai sus). O să creem un 'deployment', iar acesta o să creeze aceste Pods în spate. Metoda de folosire a comenzii este următoarea:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "kubectl create deployment NAME --image=image [--dry-run] [options]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pentru a crea un deployment trebuie să îi oferim un nume acestuia și o imagine deoarece un Pod este creat pe baza unei imagini (iar container-ul este creat pe baza acestei imagini). În continuare o să creem un deployment după imaginea de 'nginx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "kubectl create deployment nginx-deployment --image=nginx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./ScreenShots/kubectl_create_deployment_nginx.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cu această comandă o să se creeze un deployment utilizând imaginea de nginx. Comanda descarcă de pe DockerHub imaginea de nginx și creează containere pe baza acestei imagini. Output-ul comenzii ne indică faptul că acest deployment a fost creat. Cu comanda 'get deployment' (din cadrul 'kubectl') putem să afișăm informații referitoare la acest deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "kubectl get deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./ScreenShots/kubectl_get_deployment.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "După ce am creat acest deployment putem verifica în acest moment dacă s-a creat ceva Pod în cadrul acestui deployment. Pentru acesta o să utilizăm comanda 'kubectl get pod'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "kubectl get pod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./ScreenShots/kubectl_get_pod_2.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "După ce am creat acest deployment putem observa că în acest moment avem un Pod care rulează. Numele Pod-ului este prefixat de către numele deployment-ului după care se mai adaugă și un hash. Modul în care funcționează, în momentul în care am creat acest 'nginx-deployment', acest deployment are toate informațiile necesare (un blueprint) pentru a crea acest Pod. Comanda de mai sus este cea mai minimalistică metodă de a crea un deployment, îi oferim doar un nume și o imagine pe baza căreia să creeze Pods. Între deployment și Pod există alt layer care este manageriat automat de către deployment-ul kubernetes care poartă denumirea de 'replicaset'. Datele despre acest layer pot fi opțiunute utilizând comanda 'kubectl get replicaset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "kubectl get replicaset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./ScreenShots/kubectl_get_replicaset.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acest 'replicaset' are și el un nume specific și este creat din numele deployment-ului ca și prefix, plus o serie hash. Dacă se poate observa, numele Pod-ului este creat din 2 prefixe (numele deployment-ului, hash-ul 'replicaset') și la acestea se mai adaugă încă un hash."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'replicaset' se ocupă cu partea de manageriere a replicilor unui Pod. Ca și utilizator în practică nu o să avem să ne creem un 'replicaset' sau să ștergem, să modificăm o astfel de componentă, o să ne ocupăm doar de partea de deployment, în partea de deployment se poate modifica blueprint-ul acestuia și există posibilitatea să specificăm câte replici să fie în cadrul Node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toate modificările care trebuie să se realizeze în partea de deployment o să fie realizate utilizând partea de linie de comandă din kubernetes ('kubectl'). Pentru a modifica imaginea cu care a fost creat deployment-ul 'nginx-deployment', 'kubectl' are la dispoziție opțiunea de 'edit deployment', iar pentru acesta trebuie să specificăm numele deployment-ului pe care dorim să îl modificăm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "kubectl edit nginx-deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comanda de mai sus o să ne deschisă în terminal fișierul de configurație al deployment-ului, iar în cadrul acestuia o să navigăm la secțiunea unde găsim imaginea pe baza căreia este creat Pod și o să modificăm din 'nginx' în 'nginx:1.16'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./ScreenShots/kubectl_edit_deployment.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "După ce am modificat acest fișier o să salvăm fișierul și o să ieșim din el. În terminal o să se afișeze mesajul cum că acest deployment a fost editat, dacă se rulează comanda 'kubectl get pod' se va observa că Pod-ul vechi o să fie închis și o să se creeze alt Pod în acest moment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./ScreenShots/edited_deployment.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "În kubernetes există o listă a abstractizării, iar aceasta arată așa:\n",
    "\n",
    "    1. deployment\n",
    "\n",
    "    2. replicaset\n",
    "\n",
    "    3. pod\n",
    "\n",
    "    4. container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tot ce se găsește mai jos de partea de 'deployment' o să fie manageriat de kubernetes, de aceea dacă am modificat deployment-ul anterior s-au modificat și Pods. Deoarece 'replicaset' se găsește mai jos de deployment și aceasta o să fie modificată. O nouă 'replicaset' va fi creată, iar în cea anterioară se va observa că nu mai are niciun Pod care rulează."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./ScreenShots/kubectl_get_replicaset2.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Debugging Pods</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O altă comandă utilă pentru kubernetes este cea de 'logs'. Comanda respectivă afișează ce se loghează de către aplicația care rulează în cadrul Pod. Sintaxa comenzii este următoarea: kubectl logs [pod name]. Deoarece numele unui Pod este greu de reținut este recomandat să se afișeze inițial Pods (kubectl get pod) și să se ia cu copy paste numele Pod la care dorim să facem referire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "kubectl get pod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "kubectl logs nginx-deployment-6cdd747bb4-6sgbg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./ScreenShots/kubectl_logs.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pentru comanda de mai sus nu există niciun output deoarece aplicația nu a scris niciun log (așa este setată). În continuare o să creem un deployment utilizând imaginea de MongoDB (mongo) care o să scrie anumie log-uri în momentul în care se creează un container pe baza imaginii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "kubectl create deployment mongo-deployment --image=mongo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./ScreenShots/kubectl_logs_mongo.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Din moment ce Pod-ul rulează în cadrul container-ului putem să afișăm log-uril ce au fost scrise de către aplicație. Log-urile respective pot ajuta foarte mult la partea de debugging în cazul în care există ceva erori în container și nu rulează în modul în care acesta ar trebui."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./ScreenShots/kubectl_logs_mongo2.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O altă comandă utilă pentru kubernetes este comanda 'exec' (precum cea din Docker). Această comandă ne permite sî intrăm în cadrul interiorul containerului ce se rulează sub formă de terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "kubectl exec -it mongo-deployment-686c5687fb-x7w8z -- bash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Argumentul '-it' specifică să se deschidă un terminal în modul interactiv, iar partea de la final ('-- bash') reprezintă comanda care să fie executată în paralel cu comanda default ce se execută în imaginea docker. Comanda este utilă pentru partea de debuggind, prin această comandă se poate intra în terminal în container-ul respectiv, iar de acolo se pot realiza anumite modificări dacă este necesar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./ScreenShots/kubectl_exec.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fel cum cu ajutorul 'kubectl' se creează un deployment (care creează automat 'replicaset' și Pods), tot utilizând linia de comandă 'kubectl' se pot șterge aceste deployment. Pentru a șterge un deployment se va utiliza comanda 'delete deployment' urmată de numele deployment-ului pe care dorim să îl ștergem. Comanda de 'delete deployment' o să șteargă și tot ce se găsește mai jos de deployment, și anume replicaset și Pods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "kubectl detele deployment mongo-deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./ScreenShots/kubectl_delete.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se poate observa că din moment ce s-a șters deployment-ul 'mongo-deployment', atât 'replicaset' și Pods ce au ținut de acest deployment au fost șterse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inițial, când am creat aceste deployment-uri am specificat doar elementele necesare pentru a se crea un deployment, și anume partea de name a deploymentului repsectiv și imaginea docker pe baza căreia să se creeze Pods. De foarte multe ori, în momentul în care se creează in deployment pentru acesta trebuie specificate mai multe opțiuni. Pentru a nu scrie o linie de comandă extrem de lungă și de complicată, de cele mai multe pri să utilăm partea de 'configuration file' din kubernetes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Componentele care sunt creat, imaginea pe care o va utiliza deployment-ul și oricare alte opțiuni, toate o să fie trecute în cadrul acestui fișier de configurare, iar noi doar o să îi spunem lui 'kubectl' să execute acel fișier de configurare. Modul prin care se realizează acest pas este utilizând comanda 'kubectl apply'. Comanda respectivă ia un fișier de configurație ca și parametru și execută tot ce este trecut în acel fișier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "kubectl apply -f [file name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fișierul respectiv este de tipul .yaml și în el sunt prezente toate informațiile necesare pentru a crea și rula un deployment. O să creem un fișier nginx-deployment.yaml unde o să trecem informațiile necesare pentru a crea și rula un deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./ScreenShots/nginx_yaml.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fișierul respectiv este cel din imaginea de sus. 'kind: Deployment' îi specifică lui kubernetes să creeze un Deployment, iar pentru acest deployment, în 'metadata' se trece numele deployment-ului pe care dorim să îl aibă ('name: nginx-deployment'). Cu linia 'replicas: 1' se specifică câte replici ale unui Pod să se creeze în acest Node. Ce este trecut în partea de 'template' (și mai jos de acesta) reprezintă blueprint-ul pentru Pod-urile care o să fie create în cadrul unui Worker Node. Pentru a crea containere se va utiliza imaginea de nginx care o să fie luată de pe Docker Hub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dacă se rulează comanda 'kubectl apply -f nginx-deployment.yaml', acest deployment ar trebuie să se creeze automat cu un Pod în cadrul acestui deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "kubectl apply -f nginx-deployment.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./ScreenShots/kubectl_apply.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se poate observa că acest deployment a fost creat și rulează corect. Dacă se dorește să se modifice ceva anume în cadrul acestui deployment, în momentul acesta se poate modifica în cadrul fițierului local. În continuare o să modificăm fișierul de configurație ca acesta să aibă 2 replici."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./ScreenShots/nginx_yaml2.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "După ce am realizat acestă modificare în cadrul fișierului de configurație se poate rula din nou comanda 'kubectl apply -f nginx-deployment.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "kubectl apply -f nginx-deployment.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kubernetes este destul de deștept încât să știe dacă să creeze sau doar să facă update la un deployment. În prima parte, când s-a rulat comanda 'kubectl apply -f nginx-deployment.yaml' kubernetes a creat acest deployment, iar după ce am modificat în cadrul fișierului de configurație și am rulat din nou comanda, acest deployment a fost updatat. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./ScreenShots/kubectl_apply2.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Și din output-ul comenzii se poate observa că doar s-a făcut update la deployment, nu a fost creat un deployment nou (deployment.apps/nginx-deployment configured)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>YAML configuration file</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fiecare fișier de configurație din Kubernetes are 3 părți.\n",
    "\n",
    "Prima parte este reprezentată de metadata (informațiile, datele despre deployment, service, sau ce se creează). A doua parte este reprezentată de către specificații  , specificații pentru componenta care se dorește să fie creată. Atributele din partea de specificații o să fie diferite în funcție de tipul (kind) de componentă pe care îl creem (deployment, service)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cea de a 3-a partea din cadrul fișierului de configurație este reprezentat de un status. Acest 'status' este adăugat și manageriat automat de către kubernetes. Kubernetes face o comparație între fișierul de configurație yaml (ceea ce se dorește să existe în cluster) și ceea ce anume există în cluster. De exemplu dacă în fișier se specifică că se dorește să fie 2 replici, dar numai 1 este activă kubernetes depistează această diferență între ce anume există (doar 1 replică) și ce se dorește să existe (2 replici) și încearcă remedierea problemei cât mai rapid. Această a 3-a parte de 'status' își ia informațiile necesare din partea de 'etcd'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "După cum se preciza, un deployment se ocupă cu tot ce ține de Pods, acestea fiind configurate în cadrul fișierului yaml. Unde anume se găsește această configurare? Prima parte de 'spec' din cadrul fișierului are o secțiune de 'template'. Această secțiune de template este împărțită la rândui în 'metadata' și 'spec'. Secțiunea de 'template' reprezintă configurația unui Pod. Practic este un fișier de configurație în interiorul altui sistem de configurație. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modul prin care conexiunea se realizează este prin utilizarea de 'labels' și 'selectors'. Partea de 'metadata' (cea pentru deployment, nu cea pentru Pod) conține partea de 'labels', iar în cadrul secțiunii de 'specs' se găsește partea de 'selectors'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "În secțiunea de 'metadata' se oferă un set de valori de tipul key-value (app: nginx), iar acest 'label' o să se 'lipească' de componenta unde anume l-am setat. Cu linia de cod 'matchLabel' match-uim un anumit Pod la deployment, iar în acest fel se știe ce Pods ține de acest deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prin partea de 'labels' din template-ul pentru Pods match-uim un Pod la un deployment. Partea de metadata din deployment are și ea o secțiune de 'labels' (secțiune care este diferită de 'labels' din template), iar prin aceasta se va face conexiunea cu un 'Service' (unde în service va exista linia de cod 'selector: app: nginx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Următorul lucru care trebuie configurat în cadrul fișierului de configurație (valabil pentru Pods și Service) îl reprezintă port-urile. Un Service are o secțiune separată pentru porturi, iar un container din cadrul unui Pod trebuie să ruleze pe un anumit port. Partea de service are un port unde Service-ul în sine este accesibil (poartă denumirea de 'port'), dar service-ul trebuie să știe către ce Pod trebuie să trimită mai departe request-ul, dar și ce port a deschis acel Pod (poartă denumirea de 'targetPort'). Acest 'targetPort' trebuie să fie la fel ca și port-ul deschis în cadrul container-ului din Pod (un port din container se deschide prin comanda 'containerPort' și trebuie să aibă aceeași valoare ca 'targetPort')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
